{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Leaning Exercise 3: Multi-class Classification and Neural Networks\n",
    "\n",
    "From Week 4 of Coursera course, Machine Learning by Andrew Ng: https://www.coursera.org/learn/machine-learning/. The topic is the logistic regression for clustering.\n",
    "\n",
    "Eric Nam, https://github.com/eric-nam, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size = 400  # 20x20 Input Images of Digits\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the dataset from a MATLAB file\n",
    "The dataset contains 5,000 hand-written images in rows of a matrix (X) and labels in a vector (y). Each row is an unrolled 20 by 20 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MAT\n",
    "fpath_mat = \"ex3data1.mat\"\n",
    "file = MAT.matopen(fpath_mat)\n",
    "X = MAT.read(file, \"X\")\n",
    "y = vec(MAT.read(file, \"y\"))\n",
    "MAT.close(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot random 100 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using StatsBase\n",
    "n = 10\n",
    "rows = sample(1:size(X)[1], n * n, replace=false)  # Sample 100 randomly\n",
    "px = isqrt(size(X)[2])\n",
    "# Combine into one big image\n",
    "image = zeros(px * n, px * n)\n",
    "for i in 0:n-1\n",
    "    for j in 0:n-1\n",
    "        image[i * px + 1: (i + 1) * px, j * px + 1: (j + 1) * px] = X[rows[i * n + j + 1], :]\n",
    "    end\n",
    "end\n",
    "heatmap(image[end:-1:1, :], c=cgrad(:grays))   # Needs to be flipped upside down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a cost and cost gradient function\n",
    "They are copied from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    sigmoid(z)\n",
    "\n",
    "Calculate the sigmoid function, ``g(z) = \\\\frac{1}{1 + e^{-z}}``\n",
    "\n",
    "# Argument\n",
    "- `z::Number`: input variable\n",
    "\n",
    "# Return\n",
    "`Number`\n",
    "\"\"\"\n",
    "function sigmoid(z)\n",
    "    1.0 / (1.0 + exp(-z))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    cost(theta, x, y, lambda)\n",
    "\n",
    "Compute the cost with with the dataset and theta\n",
    "\n",
    "# Arguments\n",
    "- `theta::{Number, 1}`: the coefficients of the cost function\n",
    "- `x::Array{Number, 2}` : the independent variable matrix. The rows are examples, the columns features.\n",
    "This matrix has the first column filled with ones.\n",
    "- `y::Array{Number, 1}` : the dependent vector.\n",
    "- `lambda::Number` : regularization coefficient\n",
    "\n",
    "# Returns\n",
    "`::Number`: cost\n",
    "\"\"\"\n",
    "function cost(theta, x, y, lambda)\n",
    "    m, _ = size(x)\n",
    "    sig = sigmoid.(x * theta)\n",
    "    (- y' * log.(sig) - (1.0 .- y)' * log.(1.0 .- sig)) / m + lambda * 0.5 / m * (theta[2:end]' * theta[2:end])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    ∇cost(theta, x, y, lambda)\n",
    "\n",
    "Compute the cost with with the dataset and theta\n",
    "\n",
    "# Arguments\n",
    "- `theta::{Number, 1}`: the coefficients of the cost function\n",
    "- `x::Array{Number, 2}` : the independent variable matrix. The rows are examples, the columns features.\n",
    "This matrix has the first column filled with ones.\n",
    "- `y::Array{Number, 1}` : the dependent vector.\n",
    "- `lambda::Number` : regularization coefficient\n",
    "\n",
    "# Returns\n",
    "`::Array{Number, 1}`: cost gradient\n",
    "\"\"\"\n",
    "function ∇cost(theta, x, y, lambda)\n",
    "    m, n = size(x)\n",
    "    sig = sigmoid.(x * theta)\n",
    "    lambdas = fill(lambda, n)\n",
    "    lambdas[1] = 0.\n",
    "    (x' * (sig - y) + lambdas .* theta) / m\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_t = [-2, -1, 1, 2]\n",
    "X_t = hcat(ones(5), reshape(1:15, (5, 3)) / 10.)\n",
    "y_t = [1, 0, 1, 0, 1] .>= 0.5\n",
    "lambda_t = 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost(theta_t, X_t, y_t, lambda_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "∇cost(theta_t, X_t, y_t, lambda_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-vs-all training\n",
    "Find solutions using the cost and gradient function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = size(X)\n",
    "x = hcat(ones(m), X)\n",
    "lambda = 0.1\n",
    "theta_init = zeros(n + 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing ten one-vs-all cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = map(label -> Optim.minimizer(optimize(t -> cost(t, x, y .== label, lambda), \n",
    "                                               t -> ∇cost(t, x, y .== label, lambda),\n",
    "                                               theta_init, \n",
    "                                               inplace=false)),\n",
    "             1:10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = hcat(thetas...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the solution to the data and compare with the labels\n",
    "The expected accuracy from the problem is 94.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(map(x -> x[2], argmax(x * thetas, dims=2)) .== y) / m * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the weight from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MAT\n",
    "fpath_mat = \"ex3weights.mat\"\n",
    "file = MAT.matopen(fpath_mat)\n",
    "println(MAT.names(file))\n",
    "theta1 = MAT.read(file, \"Theta1\")\n",
    "theta2 = MAT.read(file, \"Theta2\")\n",
    "MAT.close(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size  = 400 # 20x20 Input Images of Digits\n",
    "hidden_layer_size = 25  # 25 hidden units\n",
    "num_labels = 10         # 10 labels, from 1 to 10   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation1 = sigmoid.(x * theta1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick the maximum activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = map(x -> x[2], argmax(hcat(ones(size(activation1)[1]), activation1) * theta2', dims=2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the accuracy\n",
    "The answer would be 97.5% from the instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum(predictions .== y) / m * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interactive part of the exercise is skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
